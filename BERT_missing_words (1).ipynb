{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17WhT5QobPJd"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "def predict_missing_word(sentence):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Tokenize the input sentence\n",
        "    tokenized_text = tokenizer.tokenize(sentence)\n",
        "\n",
        "    # Find the position of the masked token '[MASK]'\n",
        "    mask_token_index = tokenized_text.index('[MASK]')\n",
        "\n",
        "    # Convert token to vocabulary indices\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "    # Predict missing word\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tokens_tensor)\n",
        "        predictions = outputs[0][0, mask_token_index].topk(5)  # Get top 5 predictions\n",
        "\n",
        "    # Convert prediction indices back to tokens\n",
        "    predicted_tokens = [tokenizer.convert_ids_to_tokens([index.item()])[0] for index in predictions.indices]\n",
        "\n",
        "    return predicted_tokens\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentences with missing words\n",
        "sentence1 = \"I want to [MASK] a new book.\"\n",
        "sentence2 = \"The cat is sitting on the [MASK].\"\n",
        "sentence3 = \"She went to the store to buy some [MASK].\"\n",
        "\n"
      ],
      "metadata": {
        "id": "V7QsU5FYb_co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict missing word for each sentence\n",
        "predicted_words1 = predict_missing_word(sentence1)\n",
        "predicted_words2 = predict_missing_word(sentence2)\n",
        "predicted_words3 = predict_missing_word(sentence3)\n",
        "\n",
        "# Print the predicted words for each sentence\n",
        "print(predicted_words1)\n",
        "print(predicted_words2)\n",
        "print(predicted_words3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQvzdJekehGP",
        "outputId": "575514ef-4fe8-457d-ec1c-9ad6e0271245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['be', 'get', 'write', 'see', 'have']\n",
            "['door', 'cat', 'bed', 'wall', 'screen']\n",
            "['.', '\"', 'more', ',', 'the']\n"
          ]
        }
      ]
    }
  ]
}